{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from .csv files\n",
    "X_train = pd.read_csv('data/dengue_features_train.csv')\n",
    "y_train = pd.read_csv('data/dengue_labels_train.csv')\n",
    "# Drop columns year and start date\n",
    "X_train = X_train.drop(X_train.columns[[1, 3]], axis=1)\n",
    "\n",
    "# Separate the cities into two files\n",
    "X_train_sj = X_train.loc[X_train.city == 'sj']\n",
    "X_train_iq = X_train.loc[X_train.city == 'iq']\n",
    "y_train_sj = y_train.loc[y_train.city == 'sj']\n",
    "y_train_iq = y_train.loc[y_train.city == 'iq']\n",
    "del y_train_sj['city']\n",
    "del y_train_iq['city']\n",
    "del X_train_sj['city']\n",
    "del X_train_iq['city']\n",
    "\n",
    "y_train_sj = np.array(y_train_sj.drop(y_train_sj.columns[:2], axis =1))\n",
    "y_train_iq = np.array(y_train_iq.drop(y_train_iq.columns[:2], axis=1))\n",
    "# print(X_test_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all missing values with a mean value\n",
    "imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)\n",
    "imp1 = Imputer(strategy='mean')\n",
    "\n",
    "X_train_arr_sj = imp.fit_transform(X_train_sj)\n",
    "X_train_arr_iq = imp1.fit_transform(X_train_iq)\n",
    "y_train_arr_sj = imp.fit_transform(y_train_sj)\n",
    "y_train_arr_iq = imp1.fit_transform(y_train_iq)\n",
    "\n",
    "# print(X_test_arr_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_arr_sj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n"
     ]
    }
   ],
   "source": [
    "# This is for training only\n",
    "# divide the training sets into train, test, validation\n",
    "X_train_sj1, X_test_sj1, y_train_sj1, y_test_sj1 = model_selection.train_test_split(X_train_arr_sj, y_train_arr_sj, \n",
    "                                                                    test_size=0.2, random_state=42)\n",
    "X_train_sj1, X_val_sj1, y_train_sj1, y_val_sj1   = model_selection.train_test_split(X_train_sj1, y_train_sj1, \n",
    "                                                                    test_size=0.5, random_state=42)\n",
    "\n",
    "feature_columns_sj = tf.contrib.learn.infer_real_valued_columns_from_input(X_train_sj1)\n",
    "regressor_sj = xgb.XGBRegressor(n_estimators = 550, # number of boosted trees\n",
    "                             learning_rate = 0.00402047, # step size shrinkage used in update to prevent overfitting\n",
    "                             max_depth = 15, # maximum depth of a tree\n",
    "                             subsample = 0.9815, # subsample ratio of the training set (Stochastic gradient boosting)\n",
    "                             colsample_bytree = 0.701) # subsample features\n",
    "\n",
    "X_train_iq1, X_test_iq1, y_train_iq1, y_test_iq1 = model_selection.train_test_split(X_train_arr_iq, y_train_arr_iq, \n",
    "                                                                    test_size=0.2, random_state=42)\n",
    "X_train_iq1, X_val_iq1, y_train_iq1, y_val_iq1  = model_selection.train_test_split(X_train_arr_iq, y_train_arr_iq, \n",
    "                                                                    test_size=0.5, random_state=42)\n",
    "\n",
    "feature_columns_iq = tf.contrib.learn.infer_real_valued_columns_from_input(X_train_iq1)\n",
    "regressor_iq = xgb.XGBRegressor(n_estimators = 490, # number of boosted trees\n",
    "                             learning_rate = 0.00202047, # step size shrinkage used in update to prevent overfitting\n",
    "                             max_depth = 10, # maximum depth of a tree\n",
    "                             subsample = 0.6815, # subsample ratio of the training set (Stochastic gradient boosting)\n",
    "                             colsample_bytree = 0.701) # subsample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.701,\n",
       "       gamma=0, learning_rate=0.00202047, max_delta_step=0, max_depth=10,\n",
       "       min_child_weight=1, missing=None, n_estimators=490, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=0.6815)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and predict.\n",
    "regressor_sj.fit(X_train_sj1, y_train_sj1.ravel()) # ravel to make a column-vector into a 1d array\n",
    "regressor_iq.fit(X_train_iq1, y_train_iq1.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_sj = list(regressor_sj.predict(X_val_sj1))\n",
    "score_sj = mean_absolute_error(y_val_sj1, predictions_sj)\n",
    "\n",
    "predictions_iq = list(regressor_iq.predict(X_val_iq1))\n",
    "score_iq = mean_absolute_error(y_val_iq1, predictions_iq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_sj: 18.752811 Accuracy_iq: 6.183146\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy_sj: {0:f}'.format(score_sj), 'Accuracy_iq: {0:f}'.format(score_iq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_sj: 19.475421 Accuracy_iq: 5.511176\n"
     ]
    }
   ],
   "source": [
    "predictions_sj = list(regressor_sj.predict(X_test_sj1))\n",
    "score_sj = mean_absolute_error(y_test_sj1, predictions_sj)\n",
    "\n",
    "predictions_iq = list(regressor_iq.predict(X_test_iq1))\n",
    "score_iq = mean_absolute_error(y_test_iq1, predictions_iq)\n",
    "\n",
    "print('Accuracy_sj: {0:f}'.format(score_sj), 'Accuracy_iq: {0:f}'.format(score_iq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
