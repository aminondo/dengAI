{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation of a simple MLP network with one hidden layer. Tested on the iris data set.\n",
    "# Requires: numpy, sklearn>=0.18.1, tensorflow>=1.0\n",
    "\n",
    "# NOTE: In order to make the code simple, we rewrite x * W_1 + b_1 = x' * W_1'\n",
    "# where x' = [x | 1] and W_1' is the matrix W_1 appended with a new row with elements b_1's.\n",
    "# Similarly, for h * W_2 + b_2\n",
    "# for dengai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make function to preprocess data\n",
    "def preprocess_data(data_path, labels_path=None):\n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path)\n",
    "        #df = df.join(labels)\n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sj_features = df[df.city == 'sj']\n",
    "    iq_features = df[df.city == 'iq']\n",
    "    if labels_path:\n",
    "        sj_labels = labels[labels.city == 'sj']\n",
    "        iq_labels = labels[labels.city == 'iq']    \n",
    "        return sj_features, iq_features, sj_labels, iq_labels\n",
    "    return sj_features, iq_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_features, iq_features, sj_labels, iq_labels = preprocess_data(\n",
    "                                                                'data/dengue_features_train.csv',\n",
    "                                                                labels_path=\"data/dengue_labels_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load final test data\n",
    "sj_test_final, iq_test_final = preprocess_data(\"data/dengue_features_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    5\n",
       "2    4\n",
       "3    3\n",
       "4    6\n",
       "Name: total_cases, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping date and city as city already divided\n",
    "\n",
    "iq_features = iq_features.drop(iq_features.columns[[0,3]], axis=1)\n",
    "sj_features = sj_features.drop(sj_features.columns[[0,3]], axis=1)\n",
    "sj_test_final = sj_test_final.drop(sj_test_final.columns[[0,3]], axis=1)\n",
    "iq_test_final = iq_test_final.drop(iq_test_final.columns[[0,3]], axis=1)\n",
    "\n",
    "#removing city, year, weekofyear from labels tables\n",
    "sj_labels = sj_labels.total_cases\n",
    "#sj_labels = sj_labels.set_index([0,2])\n",
    "iq_labels = iq_labels.total_cases\n",
    "\n",
    "\n",
    "sj_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since data is linear it makes sense to separate data linearly\n",
    "#split train and test data\n",
    "sj_train = sj_features.head(800)\n",
    "sj_train_target = sj_labels.head(800)\n",
    "sj_test = sj_features.tail(sj_features.shape[0] - 800)\n",
    "sj_test_target = sj_labels.tail(sj_labels.shape[0] - 800)\n",
    "\n",
    "\n",
    "\n",
    "iq_train = iq_features.head(400)\n",
    "iq_train_target = iq_labels.head(400)\n",
    "iq_test = iq_features.tail(iq_features.shape[0] - 400)\n",
    "iq_test_target = iq_labels.tail(iq_labels.shape[0] - 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#randomly separating data\n",
    "# splitting data into training set and validation set\n",
    "\n",
    "sj_train, sj_test, sj_train_target, sj_test_target = train_test_split(sj_features, sj_labels, test_size=0.2, random_state=41)\n",
    "\n",
    "iq_train, iq_test, iq_train_target, iq_test_target = train_test_split(iq_features, iq_labels, test_size=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>ndvi_ne</th>\n",
       "      <th>ndvi_nw</th>\n",
       "      <th>ndvi_se</th>\n",
       "      <th>ndvi_sw</th>\n",
       "      <th>precipitation_amt_mm</th>\n",
       "      <th>reanalysis_air_temp_k</th>\n",
       "      <th>reanalysis_avg_temp_k</th>\n",
       "      <th>reanalysis_dew_point_temp_k</th>\n",
       "      <th>...</th>\n",
       "      <th>reanalysis_precip_amt_kg_per_m2</th>\n",
       "      <th>reanalysis_relative_humidity_percent</th>\n",
       "      <th>reanalysis_sat_precip_amt_mm</th>\n",
       "      <th>reanalysis_specific_humidity_g_per_kg</th>\n",
       "      <th>reanalysis_tdtr_k</th>\n",
       "      <th>station_avg_temp_c</th>\n",
       "      <th>station_diur_temp_rng_c</th>\n",
       "      <th>station_max_temp_c</th>\n",
       "      <th>station_min_temp_c</th>\n",
       "      <th>station_precip_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1991</td>\n",
       "      <td>41</td>\n",
       "      <td>0.09300</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.145083</td>\n",
       "      <td>0.168167</td>\n",
       "      <td>32.10</td>\n",
       "      <td>299.562857</td>\n",
       "      <td>299.671429</td>\n",
       "      <td>295.887143</td>\n",
       "      <td>...</td>\n",
       "      <td>55.10</td>\n",
       "      <td>80.515714</td>\n",
       "      <td>32.10</td>\n",
       "      <td>17.344286</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>27.657143</td>\n",
       "      <td>6.614286</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.8</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1992</td>\n",
       "      <td>33</td>\n",
       "      <td>0.16395</td>\n",
       "      <td>0.126650</td>\n",
       "      <td>0.215057</td>\n",
       "      <td>0.219271</td>\n",
       "      <td>65.55</td>\n",
       "      <td>299.215714</td>\n",
       "      <td>299.221429</td>\n",
       "      <td>296.007143</td>\n",
       "      <td>...</td>\n",
       "      <td>81.80</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>65.55</td>\n",
       "      <td>17.415714</td>\n",
       "      <td>1.957143</td>\n",
       "      <td>27.671429</td>\n",
       "      <td>7.557143</td>\n",
       "      <td>31.7</td>\n",
       "      <td>22.8</td>\n",
       "      <td>41.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>2007</td>\n",
       "      <td>16</td>\n",
       "      <td>0.06890</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>0.108357</td>\n",
       "      <td>0.085029</td>\n",
       "      <td>0.00</td>\n",
       "      <td>299.335714</td>\n",
       "      <td>299.557143</td>\n",
       "      <td>294.507143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.22</td>\n",
       "      <td>74.832857</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.854286</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.728571</td>\n",
       "      <td>8.014286</td>\n",
       "      <td>33.3</td>\n",
       "      <td>22.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1996</td>\n",
       "      <td>25</td>\n",
       "      <td>0.07125</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>0.156171</td>\n",
       "      <td>47.93</td>\n",
       "      <td>298.490000</td>\n",
       "      <td>298.564286</td>\n",
       "      <td>295.435714</td>\n",
       "      <td>...</td>\n",
       "      <td>73.70</td>\n",
       "      <td>83.322857</td>\n",
       "      <td>47.93</td>\n",
       "      <td>16.810000</td>\n",
       "      <td>1.928571</td>\n",
       "      <td>26.442857</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.8</td>\n",
       "      <td>84.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>2003</td>\n",
       "      <td>35</td>\n",
       "      <td>0.07260</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.204371</td>\n",
       "      <td>0.160357</td>\n",
       "      <td>98.68</td>\n",
       "      <td>300.668571</td>\n",
       "      <td>300.728571</td>\n",
       "      <td>297.048571</td>\n",
       "      <td>...</td>\n",
       "      <td>50.86</td>\n",
       "      <td>80.797143</td>\n",
       "      <td>98.68</td>\n",
       "      <td>18.571429</td>\n",
       "      <td>2.542857</td>\n",
       "      <td>27.914286</td>\n",
       "      <td>6.457143</td>\n",
       "      <td>31.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  weekofyear  ndvi_ne   ndvi_nw   ndvi_se   ndvi_sw  \\\n",
       "75   1991          41  0.09300  0.093000  0.145083  0.168167   \n",
       "119  1992          33  0.16395  0.126650  0.215057  0.219271   \n",
       "882  2007          16  0.06890  0.044267  0.108357  0.085029   \n",
       "319  1996          25  0.07125  0.064600  0.146100  0.156171   \n",
       "693  2003          35  0.07260  0.100000  0.204371  0.160357   \n",
       "\n",
       "     precipitation_amt_mm  reanalysis_air_temp_k  reanalysis_avg_temp_k  \\\n",
       "75                  32.10             299.562857             299.671429   \n",
       "119                 65.55             299.215714             299.221429   \n",
       "882                  0.00             299.335714             299.557143   \n",
       "319                 47.93             298.490000             298.564286   \n",
       "693                 98.68             300.668571             300.728571   \n",
       "\n",
       "     reanalysis_dew_point_temp_k        ...          \\\n",
       "75                    295.887143        ...           \n",
       "119                   296.007143        ...           \n",
       "882                   294.507143        ...           \n",
       "319                   295.435714        ...           \n",
       "693                   297.048571        ...           \n",
       "\n",
       "     reanalysis_precip_amt_kg_per_m2  reanalysis_relative_humidity_percent  \\\n",
       "75                             55.10                             80.515714   \n",
       "119                            81.80                             82.750000   \n",
       "882                             2.22                             74.832857   \n",
       "319                            73.70                             83.322857   \n",
       "693                            50.86                             80.797143   \n",
       "\n",
       "     reanalysis_sat_precip_amt_mm  reanalysis_specific_humidity_g_per_kg  \\\n",
       "75                          32.10                              17.344286   \n",
       "119                         65.55                              17.415714   \n",
       "882                          0.00                              15.854286   \n",
       "319                         47.93                              16.810000   \n",
       "693                         98.68                              18.571429   \n",
       "\n",
       "     reanalysis_tdtr_k  station_avg_temp_c  station_diur_temp_rng_c  \\\n",
       "75            2.257143           27.657143                 6.614286   \n",
       "119           1.957143           27.671429                 7.557143   \n",
       "882           3.000000           27.728571                 8.014286   \n",
       "319           1.928571           26.442857                 5.800000   \n",
       "693           2.542857           27.914286                 6.457143   \n",
       "\n",
       "     station_max_temp_c  station_min_temp_c  station_precip_mm  \n",
       "75                 31.7                22.8                8.3  \n",
       "119                31.7                22.8               41.9  \n",
       "882                33.3                22.8                1.8  \n",
       "319                30.6                22.8               84.6  \n",
       "693                31.7                23.3               69.6  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75     116\n",
       "119     30\n",
       "882      4\n",
       "319      6\n",
       "693     32\n",
       "Name: total_cases, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sj_train_target.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop(X, w_1, w_2, w_3):\n",
    "    \"\"\"\n",
    "    Forward-propagation.\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "    \"\"\"\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    h2 = tf.nn.sigmoid(tf.matmul(h, w_2))\n",
    "    yhat = tf.matmul(h2, w_3)  # The \\varphi function\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer's sizes San Juan\n",
    "x_size = sj_train.shape[1]   # Number of input nodes\n",
    "h_size = 256                # Number of hidden nodes\n",
    "y_size = 1   # Number of outcomes (3 iris flowers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Symbols\n",
    "X = tf.placeholder(\"float\", shape=[None, x_size])\n",
    "y = tf.placeholder(\"float\", shape=[None, y_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weight initializations\n",
    "w_1 = init_weights((x_size, h_size))\n",
    "w_2 = init_weights((h_size, h_size))\n",
    "w_3 = init_weights((h_size, y_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "yhat    = forwardprop(X, w_1, w_2, w_3)\n",
    "predict = tf.to_int64(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "cost    = tf.losses.mean_squared_error(labels=y, predictions=yhat)\n",
    "updates = tf.train.GradientDescentOptimizer(0.00000003).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transposing labels so that it works in tensorflow\n",
    "sj_train_target = sj_train_target.as_matrix()\n",
    "iq_train_target = iq_train_target.as_matrix()\n",
    "\n",
    "sj_train_target = sj_train_target[:, None]\n",
    "iq_train_target = iq_train_target[:, None]\n",
    "\n",
    "sj_test_target = sj_test_target.as_matrix()\n",
    "iq_test_target = iq_test_target.as_matrix()\n",
    "\n",
    "sj_test_target = sj_test_target[:, None]\n",
    "iq_test_target = iq_test_target[:, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sj_train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run SGD\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train loss = 34.18, test loss = 29.26\n",
      "Epoch = 11, train loss = 32.33, test loss = 27.41\n",
      "Epoch = 21, train loss = 31.46, test loss = 26.51\n",
      "Epoch = 31, train loss = 30.67, test loss = 25.72\n",
      "Epoch = 41, train loss = 29.94, test loss = 24.99\n",
      "Epoch = 51, train loss = 28.71, test loss = 23.85\n",
      "Epoch = 61, train loss = 28.16, test loss = 23.32\n",
      "Epoch = 71, train loss = 27.67, test loss = 22.84\n",
      "Epoch = 81, train loss = 27.24, test loss = 22.44\n",
      "Epoch = 91, train loss = 26.86, test loss = 22.09\n",
      "Epoch = 101, train loss = 26.52, test loss = 21.80\n",
      "Epoch = 111, train loss = 26.23, test loss = 21.59\n",
      "Epoch = 121, train loss = 26.00, test loss = 21.43\n",
      "Epoch = 131, train loss = 25.81, test loss = 21.31\n",
      "Epoch = 141, train loss = 25.67, test loss = 21.24\n",
      "Epoch = 151, train loss = 25.60, test loss = 21.27\n",
      "Epoch = 161, train loss = 25.60, test loss = 21.24\n",
      "Epoch = 171, train loss = 25.56, test loss = 21.31\n",
      "Epoch = 180, train loss = 25.57, test loss = 21.40\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(180):\n",
    "        # Train with each example\n",
    "        for i in range(len(sj_train)):\n",
    "            sess.run(updates, feed_dict={X: sj_train[i: i + 1], y: sj_train_target[i: i + 1]})\n",
    "\n",
    "        train_MAE = metrics.mean_absolute_error(sj_train_target,\n",
    "                                                     sess.run(predict, feed_dict={X: sj_train}))\n",
    "        test_MAE  = metrics.mean_absolute_error(sj_test_target,\n",
    "                                                     sess.run(predict, feed_dict={X: sj_test}))\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 179:\n",
    "            print(\"Epoch = %d, train loss = %.2f, test loss = %.2f\"\n",
    "                  % (epoch + 1, train_MAE, test_MAE))\n",
    "#run model on final test data\n",
    "sj_predictions = sess.run(predict, feed_dict={X: sj_test_final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run model again but for Iquitos, no need to redo x_size since have same number of variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train loss = 7.33, test loss = 8.49\n",
      "Epoch = 11, train loss = 6.80, test loss = 8.06\n",
      "Epoch = 21, train loss = 6.69, test loss = 7.91\n",
      "Epoch = 31, train loss = 6.69, test loss = 7.91\n",
      "Epoch = 41, train loss = 6.69, test loss = 7.91\n",
      "Epoch = 51, train loss = 6.69, test loss = 7.91\n",
      "Epoch = 61, train loss = 6.69, test loss = 7.91\n",
      "Epoch = 71, train loss = 6.69, test loss = 7.91\n",
      "Epoch = 81, train loss = 6.69, test loss = 7.91\n",
      "Epoch = 91, train loss = 6.27, test loss = 7.43\n",
      "Epoch = 101, train loss = 6.26, test loss = 7.41\n",
      "Epoch = 111, train loss = 6.25, test loss = 7.41\n",
      "Epoch = 121, train loss = 6.25, test loss = 7.41\n",
      "Epoch = 131, train loss = 6.25, test loss = 7.41\n",
      "Epoch = 141, train loss = 6.25, test loss = 7.41\n",
      "Epoch = 151, train loss = 6.25, test loss = 7.41\n",
      "Epoch = 161, train loss = 6.25, test loss = 7.41\n",
      "Epoch = 171, train loss = 6.25, test loss = 7.41\n",
      "Epoch = 180, train loss = 6.24, test loss = 7.38\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(180):\n",
    "        # Train with each example\n",
    "        for i in range(len(iq_train)):\n",
    "            sess.run(updates, feed_dict={X: iq_train[i: i + 1], y: iq_train_target[i: i + 1]})\n",
    "\n",
    "        train_MAE = metrics.mean_absolute_error(iq_train_target,\n",
    "                                                     sess.run(predict, feed_dict={X: iq_train}))\n",
    "        test_MAE  = metrics.mean_absolute_error(iq_test_target,\n",
    "                                                     sess.run(predict, feed_dict={X: iq_test}))\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == 179:\n",
    "            print(\"Epoch = %d, train loss = %.2f, test loss = %.2f\"\n",
    "                  % (epoch + 1, train_MAE, test_MAE))\n",
    "#run model on final test data\n",
    "iq_predictions = sess.run(predict, feed_dict={X: iq_test_final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile into submissions format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"data/dengue_labels_test.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([sj_predictions, iq_predictions])\n",
    "submission.to_csv(\"submission_MLP.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
